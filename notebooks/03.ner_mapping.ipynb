{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0828457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aktkr\\financial-news-intelligence\\.multi_agent_langgraph\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import re, json, sqlite3\n",
    "import sqlite3, os\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad19a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/models\", exist_ok=True)\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "local_dir = \"../data/models/dslim-bert-base-ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9c47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model was taken from HuggingFace - \"https://huggingface.co/dslim/bert-base-NER\"\n",
    "\n",
    "# model_name = \"dslim/bert-base-NER\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=local_dir)\n",
    "# model = AutoModelForTokenClassification.from_pretrained(model_name, cache_dir=local_dir)\n",
    "\n",
    "# print(\"Success!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012c13fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot path: ..\\data\\models\\dslim-bert-base-ner\\models--dslim--bert-base-NER\\snapshots\\d1a3e8f13f8c3566299d95fcfc9a8d2382a9affc \n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ..\\data\\models\\dslim-bert-base-ner\\models--dslim--bert-base-NER\\snapshots\\d1a3e8f13f8c3566299d95fcfc9a8d2382a9affc were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "['HD', '##FC', 'Bank', 'RBI', 're', '##po', 'rate', 'Q', '##2']\n",
      "---\n",
      "{0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC'}\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.99932396,\n",
       "  'word': 'RBI',\n",
       "  'start': 0,\n",
       "  'end': 3},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99931717,\n",
       "  'word': 'HDFC Bank',\n",
       "  'start': 32,\n",
       "  'end': 41}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = Path(\"../data/models/dslim-bert-base-ner\")\n",
    "snapshot = list(base.glob(\"**/snapshots/*\"))[0]  # first snapshot folder\n",
    "\n",
    "print(\"Using snapshot path:\", snapshot, \"\\n---\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(snapshot)\n",
    "model = AutoModelForTokenClassification.from_pretrained(snapshot)\n",
    "\n",
    "fin_ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "print(\"---\")\n",
    "print(tokenizer.tokenize(\"HDFC Bank RBI repo rate Q2\"))\n",
    "print(\"---\")\n",
    "print(model.config.id2label)\n",
    "# print(model.config.label2id)\n",
    "print(\"---\")\n",
    "\n",
    "fin_ner(\"RBI increased the repo rate and HDFC Bank reported strong Q2 results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fab5d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article_ids</th>\n",
       "      <th>article_title</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>num_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[np.int64(1)]</td>\n",
       "      <td>Worried About Inflation? These 3 ETFs Offer Re...</td>\n",
       "      <td>Inflation has slowed but remains a major conce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[np.int64(2)]</td>\n",
       "      <td>Intel’s Black Friday Breakout: Apple Rumors Fu...</td>\n",
       "      <td>A holiday stock surge fueled by credible Apple...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[np.int64(3)]</td>\n",
       "      <td>Klarna's Crypto Play: A Plan to Fix Its Profit...</td>\n",
       "      <td>Klarna's launch of a stablecoin is a strategic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[np.int64(4)]</td>\n",
       "      <td>Meta Platforms May Ditch NVIDIA Chips—Here’s W...</td>\n",
       "      <td>Meta Platforms may be looking to alter where i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[np.int64(5)]</td>\n",
       "      <td>SoFi Technologies: From Fintech Speculation to...</td>\n",
       "      <td>SoFi Technologies is proving its long-term val...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    article_ids                                      article_title  \\\n",
       "0   1  [np.int64(1)]  Worried About Inflation? These 3 ETFs Offer Re...   \n",
       "1   2  [np.int64(2)]  Intel’s Black Friday Breakout: Apple Rumors Fu...   \n",
       "2   3  [np.int64(3)]  Klarna's Crypto Play: A Plan to Fix Its Profit...   \n",
       "3   4  [np.int64(4)]  Meta Platforms May Ditch NVIDIA Chips—Here’s W...   \n",
       "4   5  [np.int64(5)]  SoFi Technologies: From Fintech Speculation to...   \n",
       "\n",
       "                                       combined_text  num_articles  \n",
       "0  Inflation has slowed but remains a major conce...             1  \n",
       "1  A holiday stock surge fueled by credible Apple...             1  \n",
       "2  Klarna's launch of a stablecoin is a strategic...             1  \n",
       "3  Meta Platforms may be looking to alter where i...             1  \n",
       "4  SoFi Technologies is proving its long-term val...             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../data/financial_news.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "    \"\"\"\n",
    "    SELECT * FROM unique_news ORDER BY id \n",
    "    \"\"\"\n",
    ")\n",
    "stories = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"SUCCESS!!\")\n",
    "df = pd.DataFrame(stories, columns=[\n",
    "    \"id\", \"article_ids\", \"article_title\", \"combined_text\", \"num_articles\"\n",
    "])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b6891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank of America sees a credible pathway for gold prices to surge higher in the coming year as supportive macroeconomic drivers remain firmly intact.\n",
      "[{'entity_group': 'ORG', 'score': 0.9992711, 'word': 'Bank of America', 'start': 0, 'end': 15}]\n",
      "\n",
      "---\n",
      "\n",
      "Stocks were modestly higher in a shortened trading week; next week will bring a better sense of institutional sentiment heading into the holiday season\n",
      "[]\n",
      "\n",
      "---\n",
      "\n",
      "Applied Digital's stock rallied after energizing its AI campus, validating its strategy to secure multi-billion dollar contracts from power-hungry hyperscalers.\n",
      "[{'entity_group': 'ORG', 'score': 0.9991749, 'word': 'Applied Digital', 'start': 0, 'end': 15}, {'entity_group': 'ORG', 'score': 0.97146523, 'word': 'AI', 'start': 53, 'end': 55}]\n",
      "\n",
      "---\n",
      "\n",
      "Alphabet has flipped its H1 sentiment to overwhelmingly bullish, boosted by accelerating growth, the release of Gemini 3, and Berkshire’s recent stake.\n",
      "[{'entity_group': 'ORG', 'score': 0.99919915, 'word': 'Alphabet', 'start': 0, 'end': 8}, {'entity_group': 'MISC', 'score': 0.9620122, 'word': 'Gemini 3', 'start': 112, 'end': 120}, {'entity_group': 'ORG', 'score': 0.9983163, 'word': 'Berkshire', 'start': 126, 'end': 135}]\n",
      "\n",
      "---\n",
      "\n",
      "Fiserv’s RSI and MACD are both starting to flash green . If the stock can continue to stabilize, we could be looking at the mother of all comeback stories.\n",
      "[{'entity_group': 'ORG', 'score': 0.90444857, 'word': 'Fiserv', 'start': 0, 'end': 6}, {'entity_group': 'MISC', 'score': 0.893246, 'word': 'RS', 'start': 9, 'end': 11}, {'entity_group': 'ORG', 'score': 0.65720356, 'word': 'MACD', 'start': 17, 'end': 21}]\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,10):\n",
    "    sample_text = df.loc[i, \"combined_text\"]\n",
    "    print(sample_text)\n",
    "    print(fin_ner(sample_text))\n",
    "    print(\"\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75db0a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['regulators', 'indices', 'sectors', 'financial_terms', 'kpi_terms', 'companies_custom', 'products'])\n"
     ]
    }
   ],
   "source": [
    "# Gazetteer\n",
    "gazetteer_path = \"../assets/fin_gazetteers.json\"\n",
    "with open(gazetteer_path, \"r\") as f:\n",
    "    GAZ = json.load(f)\n",
    "\n",
    "print(GAZ.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4924ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICES = [x.lower() for x in GAZ[\"indices\"]]\n",
    "SECTORS = [x.lower() for x in GAZ[\"sectors\"]]\n",
    "REGULATORS = [x.lower() for x in GAZ[\"regulators\"]]\n",
    "FIN_TERMS = [x.lower() for x in GAZ[\"financial_terms\"]]\n",
    "KPI_TERMS = [x.lower() for x in GAZ[\"kpi_terms\"]]\n",
    "COMPANIES_CUSTOM = [x.lower() for x in GAZ[\"companies_custom\"]]\n",
    "PRODUCTS = [x.lower() for x in GAZ[\"products\"]]\n",
    "\n",
    "# Regex\n",
    "MONEY_REGEX = re.compile(r\"(₹\\s?\\d+[\\d,]*(?:\\.\\d+)?|\\b\\d+(\\.\\d+)?\\s?(crore|lakh|million|billion))\", re.I)\n",
    "PERCENT_REGEX = re.compile(r\"\\b\\d+(\\.\\d+)?\\s?%\")\n",
    "KPI_REGEX = re.compile(r\"\\b(Q[1-4]\\s?(results|earnings)|EBITDA|PAT|EPS|Revenue|Profit)\\b\", re.I)\n",
    "\n",
    "\n",
    "def normalize(items):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for i in items:\n",
    "        if not i: \n",
    "            continue\n",
    "        key = i.strip().lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            out.append(i.strip())\n",
    "    return out\n",
    "\n",
    "\n",
    "def match_rules(text):\n",
    "    tl = text.lower()\n",
    "\n",
    "    return {\n",
    "        \"indices\": normalize([i for i in INDICES if i in tl]),\n",
    "        \"sectors\": normalize([s for s in SECTORS if s in tl]),\n",
    "        \"regulators\": normalize([r for r in REGULATORS if r in tl]),\n",
    "        \"policies\": normalize([t for t in FIN_TERMS if t in tl]),\n",
    "        \"custom_companies\": normalize([c for c in COMPANIES_CUSTOM if c in tl]),\n",
    "        \"products\": normalize([p for p in PRODUCTS if p in tl]),\n",
    "        \"kpis\": normalize([m.group(0) for m in KPI_REGEX.finditer(text)]),\n",
    "        \"money\": normalize([m.group(0) for m in MONEY_REGEX.finditer(text)]),\n",
    "        \"percent\": normalize([m.group(0) for m in PERCENT_REGEX.finditer(text)])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d79f311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indices': ['nifty', 'nifty 50'],\n",
       " 'sectors': [],\n",
       " 'regulators': ['rbi'],\n",
       " 'policies': ['repo rate', 'inflation'],\n",
       " 'custom_companies': ['hdfc bank', 'reliance'],\n",
       " 'products': [],\n",
       " 'kpis': ['Q2 results', 'EBITDA'],\n",
       " 'money': [],\n",
       " 'percent': ['12%']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "RBI increased the repo rate by 25 bps leading to volatility in NIFTY 50. \n",
    "HDFC Bank and Reliance saw strong Q2 results with EBITDA growing 12%.\n",
    "Investors expect inflation to ease in coming quarters.\n",
    "\"\"\"\n",
    "\n",
    "rules = match_rules(sample_text)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71dda7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9991365,\n",
       "  'word': 'RBI',\n",
       "  'start': 1,\n",
       "  'end': 4},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9992687,\n",
       "  'word': 'HDFC Bank',\n",
       "  'start': 75,\n",
       "  'end': 84},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99848515,\n",
       "  'word': 'Reliance',\n",
       "  'start': 89,\n",
       "  'end': 97},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99618524,\n",
       "  'word': 'EBITDA',\n",
       "  'start': 125,\n",
       "  'end': 131}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_output = fin_ner(sample_text)\n",
    "ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f26d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = []\n",
    "people = []\n",
    "locations = []\n",
    "\n",
    "for ent in ner_output:\n",
    "    if ent[\"entity_group\"] == \"ORG\":\n",
    "        companies.append(ent[\"word\"])\n",
    "    elif ent[\"entity_group\"] == \"PER\":\n",
    "        people.append(ent[\"word\"])\n",
    "    elif ent[\"entity_group\"] == \"LOC\":\n",
    "        locations.append(ent[\"word\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f3753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_entities = {\n",
    "    \"companies\": normalize(companies + rules[\"custom_companies\"]),\n",
    "    \"people\": normalize(people),\n",
    "    \"locations\": normalize(locations),\n",
    "    \"indices\": rules[\"indices\"],\n",
    "    \"sectors\": rules[\"sectors\"],\n",
    "    \"regulators\": rules[\"regulators\"],\n",
    "    \"policies\": rules[\"policies\"],\n",
    "    \"products\": rules[\"products\"],\n",
    "    \"kpis\": rules[\"kpis\"],\n",
    "    \"money\": rules[\"money\"],\n",
    "    \"percent\": rules[\"percent\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92280b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'companies': ['RBI', 'HDFC Bank', 'Reliance', 'EBITDA'],\n",
       " 'people': [],\n",
       " 'locations': [],\n",
       " 'indices': ['nifty', 'nifty 50'],\n",
       " 'sectors': [],\n",
       " 'regulators': ['rbi'],\n",
       " 'policies': ['repo rate', 'inflation'],\n",
       " 'products': [],\n",
       " 'kpis': ['Q2 results', 'EBITDA'],\n",
       " 'money': [],\n",
       " 'percent': ['12%']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0462c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "# assume these are loaded from your fin_gazetteers.json earlier\n",
    "# COMPANIES_CUSTOM, REGULATORS, KPI_TERMS, FIN_TERMS, etc. are lowercase lists\n",
    "\n",
    "KPI_SET = set([k.lower() for k in KPI_TERMS])     # e.g. [\"q1\",\"ebitda\",...]\n",
    "FINTERM_SET = set([f.lower() for f in FIN_TERMS])\n",
    "REGULATOR_SET = set([r.lower() for r in REGULATORS])\n",
    "COMPANY_GAZETTEER = set([c.lower() for c in COMPANIES_CUSTOM])\n",
    "\n",
    "# helper regex\n",
    "PUNCT_RE = re.compile(r\"[^\\w\\s]\")\n",
    "NUMERIC_RE = re.compile(r\"^[\\d\\W_]+$\")   # tokens that are purely numbers/punct\n",
    "\n",
    "def _clean_span(s: str) -> str:\n",
    "    \"\"\"Normalize whitespace and punctuation; keep original casing for display but return cleaned lowered form for checks\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def _is_probably_company_token(token: str) -> bool:\n",
    "    t = token.strip()\n",
    "    if not t: \n",
    "        return False\n",
    "    low = t.lower()\n",
    "    # filter out exact known bad classes\n",
    "    if low in REGULATOR_SET: \n",
    "        return False\n",
    "    if low in KPI_SET or low in FINTERM_SET:\n",
    "        return False\n",
    "    # remove tokens that are punctuation or pure numbers\n",
    "    if NUMERIC_RE.match(low):\n",
    "        return False\n",
    "    # if token is short like \"Q2\" or single-letter, reject\n",
    "    if len(low) <= 2 and not low.isalpha():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def prioritize_companies(model_orgs: List[str], gaz_companies: List[str], regulators: List[str], kpis: List[str], fin_terms: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    - prefer gazetteer matches (exact or substring)\n",
    "    - then add model ORG outputs that pass the filters and do not look like kpi/regulator\n",
    "    - dedupe, keep longer names first\n",
    "    \"\"\"\n",
    "    chosen = []\n",
    "    seen = set()\n",
    "\n",
    "    # 1) add gazetteer matches (canonical)\n",
    "    for c in gaz_companies:\n",
    "        if not c: continue\n",
    "        clean = _clean_span(c)\n",
    "        low = clean.lower()\n",
    "        if low in seen: \n",
    "            continue\n",
    "        if _is_probably_company_token(clean):\n",
    "            chosen.append(clean)\n",
    "            seen.add(low)\n",
    "\n",
    "    # 2) add model ORGs if they pass filters and are not substrings of existing chosen\n",
    "    for org in model_orgs:\n",
    "        if not org: \n",
    "            continue\n",
    "        org_clean = _clean_span(org)\n",
    "        low = org_clean.lower()\n",
    "\n",
    "        # remove if looks like kpi/fin-term/regulator\n",
    "        if low in KPI_SET or low in FINTERM_SET or low in REGULATOR_SET:\n",
    "            continue\n",
    "        if not _is_probably_company_token(org_clean):\n",
    "            continue\n",
    "\n",
    "        # prefer longer names: if model org is substring of an existing chosen (eg \"HDFC\" vs \"HDFC Bank\"), skip\n",
    "        is_sub = False\n",
    "        for already in chosen:\n",
    "            if org_clean.lower() in already.lower():\n",
    "                is_sub = True\n",
    "                break\n",
    "            if already.lower() in org_clean.lower():\n",
    "                # if org_clean contains already and is longer, replace shorter\n",
    "                if already.lower() in seen:\n",
    "                    # replace shorter\n",
    "                    chosen = [x for x in chosen if x.lower() != already.lower()]\n",
    "                    seen.discard(already.lower())\n",
    "                break\n",
    "        if not is_sub:\n",
    "            chosen.append(org_clean)\n",
    "            seen.add(low)\n",
    "\n",
    "    # 3) sort by length desc so longer company names appear first (reasonable heuristic)\n",
    "    chosen = sorted(chosen, key=lambda x: -len(x))\n",
    "    return chosen\n",
    "\n",
    "def postprocess_entities(model_ner_out: List[Dict], rule_out: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    model_ner_out: list of pipeline outputs (with keys 'entity_group' and 'word')\n",
    "    rule_out: result of rule_match(text) with keys indices,sectors,regulators,custom_companies,kpis,policies,products\n",
    "    \"\"\"\n",
    "    # extract raw lists\n",
    "    model_orgs = [ _clean_span(e[\"word\"]) for e in model_ner_out if e.get(\"entity_group\",\"\").upper() in (\"ORG\",\"MISC\",\"MISCELLANEOUS\") ]\n",
    "    model_pers = [ _clean_span(e[\"word\"]) for e in model_ner_out if e.get(\"entity_group\",\"\").upper() in (\"PER\",\"PERSON\") ]\n",
    "    model_locs = [ _clean_span(e[\"word\"]) for e in model_ner_out if e.get(\"entity_group\",\"\").upper() in (\"LOC\",\"GPE\") ]\n",
    "\n",
    "    # rule outputs\n",
    "    gaz_companies = rule_out.get(\"custom_companies\", []) or []\n",
    "    regulators = rule_out.get(\"regulators\", []) or []\n",
    "    kpis = rule_out.get(\"kpis\", []) or []\n",
    "    fint = rule_out.get(\"policies\", []) or []   # financial terms\n",
    "    indices = rule_out.get(\"indices\", []) or []\n",
    "    sectors = rule_out.get(\"sectors\", []) or []\n",
    "    products = rule_out.get(\"products\", []) or []\n",
    "    money = rule_out.get(\"money\", []) or []\n",
    "    percent = rule_out.get(\"percent\", []) or []\n",
    "\n",
    "    # Build companies list with prioritization & filtering\n",
    "    companies = prioritize_companies(model_orgs, gaz_companies, regulators, kpis, fint)\n",
    "\n",
    "    # If gazetteer had a custom company and model didn't find it, ensure it is included\n",
    "    for g in gaz_companies:\n",
    "        if g and g.lower() not in [c.lower() for c in companies]:\n",
    "            companies.append(_clean_span(g))\n",
    "\n",
    "    # Final normalization / dedupe for all lists\n",
    "    def dedupe_list(lst):\n",
    "        out = []\n",
    "        seen = set()\n",
    "        for item in lst:\n",
    "            if not item: \n",
    "                continue\n",
    "            k = item.strip()\n",
    "            if k.lower() in seen:\n",
    "                continue\n",
    "            seen.add(k.lower())\n",
    "            out.append(k)\n",
    "        return out\n",
    "\n",
    "    final = {\n",
    "        \"companies\": dedupe_list(companies),\n",
    "        \"people\": dedupe_list(model_pers),\n",
    "        \"locations\": dedupe_list(model_locs),\n",
    "        \"indices\": dedupe_list(indices),\n",
    "        \"sectors\": dedupe_list(sectors),\n",
    "        \"regulators\": dedupe_list(regulators),\n",
    "        \"policies\": dedupe_list(fint),\n",
    "        \"products\": dedupe_list(products),\n",
    "        \"kpis\": dedupe_list(kpis),\n",
    "        \"money\": dedupe_list(money),\n",
    "        \"percent\": dedupe_list(percent)\n",
    "    }\n",
    "\n",
    "    # Remove any company token that exactly equals a regulator or KPI\n",
    "    final[\"companies\"] = [c for c in final[\"companies\"] if c.lower() not in REGULATOR_SET and c.lower() not in KPI_SET and c.lower() not in FINTERM_SET]\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31ace69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'companies': ['hdfc bank', 'reliance'],\n",
       " 'people': [],\n",
       " 'locations': [],\n",
       " 'indices': ['nifty', 'nifty 50'],\n",
       " 'sectors': [],\n",
       " 'regulators': ['rbi'],\n",
       " 'policies': ['repo rate', 'inflation'],\n",
       " 'products': [],\n",
       " 'kpis': ['Q2 results', 'EBITDA'],\n",
       " 'money': [],\n",
       " 'percent': ['12%']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_out = fin_ner(sample_text)             # pipeline output\n",
    "rules = match_rules(sample_text)       # gazetteer + regex\n",
    "cleaned = postprocess_entities(ner_out, rules)\n",
    "cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdcd66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_match_gazetteer(text: str, phrase_list: list):\n",
    "    \"\"\"\n",
    "    Returns a list of matched phrases using longest-match-first logic.\n",
    "    Prevents 'nifty' from matching when 'nifty 50' is present.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    matches = []\n",
    "    occupied = [False] * len(text_lower)\n",
    "\n",
    "    sorted_phrases = sorted(phrase_list, key=lambda x: -len(x))\n",
    "\n",
    "    for phrase in sorted_phrases:\n",
    "        p = phrase.lower()\n",
    "        start_idx = text_lower.find(p)\n",
    "        while start_idx != -1:\n",
    "            end_idx = start_idx + len(p)\n",
    "            if not any(occupied[start_idx:end_idx]):\n",
    "                matches.append(phrase)\n",
    "\n",
    "                for i in range(start_idx, end_idx):\n",
    "                    occupied[i] = True\n",
    "\n",
    "            start_idx = text_lower.find(p, start_idx + 1)\n",
    "\n",
    "    return list(set(matches))  # dedupe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a420da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_rules(text):\n",
    "    tl = text.lower()\n",
    "\n",
    "    return {\n",
    "        \"indices\": normalize(longest_match_gazetteer(text, INDICES)),\n",
    "        \"sectors\": normalize([s for s in SECTORS if s in tl]),\n",
    "        \"regulators\": normalize([r for r in REGULATORS if r in tl]),\n",
    "        \"policies\": normalize([t for t in FIN_TERMS if t in tl]),\n",
    "        \"custom_companies\": normalize([c for c in COMPANIES_CUSTOM if c in tl]),\n",
    "        \"products\": normalize([p for p in PRODUCTS if p in tl]),\n",
    "        \"kpis\": normalize([m.group(0) for m in KPI_REGEX.finditer(text)]),\n",
    "        \"money\": normalize([m.group(0) for m in MONEY_REGEX.finditer(text)]),\n",
    "        \"percent\": normalize([m.group(0) for m in PERCENT_REGEX.finditer(text)])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0727756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'companies': ['hdfc bank', 'reliance'],\n",
       " 'people': [],\n",
       " 'locations': [],\n",
       " 'indices': ['nifty 50'],\n",
       " 'sectors': [],\n",
       " 'regulators': ['rbi'],\n",
       " 'policies': ['repo rate', 'inflation'],\n",
       " 'products': [],\n",
       " 'kpis': ['Q2 results', 'EBITDA'],\n",
       " 'money': [],\n",
       " 'percent': ['12%']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_out = fin_ner(sample_text)             # pipeline output\n",
    "rules = match_rules(sample_text)       # gazetteer + regex\n",
    "cleaned = postprocess_entities(ner_out, rules)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/financial_news.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "            \"\"\" \n",
    "            CREATE TABLE IF NOT EXISTS news_entities (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            story_id INT,\n",
    "            article_ids TEXT,\n",
    "            article_title TEXT,\n",
    "            companies TEXT,\n",
    "            sectors TEXT,\n",
    "            people TEXT,\n",
    "            indices TEXT,\n",
    "            regulators TEXT,\n",
    "            policies TEXT,\n",
    "            products TEXT,\n",
    "            locations TEXT,\n",
    "            kpis TEXT,\n",
    "            financial_terms TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            );\n",
    "            \"\"\"\n",
    "        )\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bfd9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/financial_news.db\")\n",
    "\n",
    "def fetch_stories():\n",
    "    cur = conn.cursor()\n",
    "    sql = \"SELECT id, article_ids, article_title, combined_text, num_articles FROM unique_news ORDER BY id;\"\n",
    "    cur.execute(sql)\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5329874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '[np.int64(1)]', 'Worried About Inflation? These 3 ETFs Offer Real Protection', 'Inflation has slowed but remains a major concern for many investors; these ETFs can help provide a buffer through the use of TIPS, commodities, or T-Bills.', 1)\n"
     ]
    }
   ],
   "source": [
    "rows = fetch_stories()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b8f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "def save_entities(story, story_id, story_article_ids, story_title):\n",
    "    conn = sqlite3.connect(\"../data/financial_news.db\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "            INSERT INTO news_entities \n",
    "            (story_id, article_ids, article_title, companies, sectors, people, indices, regulators, policies, products, locations, kpis, financial_terms)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (\n",
    "                story_id,\n",
    "                story_article_ids,\n",
    "                story_title,\n",
    "                json.dumps(story.get(\"companies\", [])),\n",
    "                json.dumps(story.get(\"sectors\", [])),\n",
    "                json.dumps(story.get(\"people\", [])),\n",
    "                json.dumps(story.get(\"indices\", [])),\n",
    "                json.dumps(story.get(\"regulators\", [])),\n",
    "                json.dumps(story.get(\"policies\", [])),\n",
    "                json.dumps(story.get(\"products\", [])),\n",
    "                json.dumps(story.get(\"locations\", [])),\n",
    "                json.dumps(story.get(\"kpis\", [])),\n",
    "                json.dumps(story.get(\"financial_terms\", [])),\n",
    "            )\n",
    "        )\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "rows = fetch_stories()\n",
    "for story in rows:\n",
    "    ner_out = fin_ner(story[3])             # pipeline output\n",
    "    rules = match_rules(story[3])       # gazetteer + regex\n",
    "    cleaned = postprocess_entities(ner_out, rules)\n",
    "    save_entities(cleaned, story_id=story[0], story_article_ids=story[1], story_title=story[2])\n",
    "\n",
    "print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dfa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".multi_agent_langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
